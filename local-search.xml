<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>项目</title>
    <link href="/2025/03/02/%E9%A1%B9%E7%9B%AE/"/>
    <url>/2025/03/02/%E9%A1%B9%E7%9B%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h1><h2 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h2><p>多副本状态机，解决<strong>强一致性</strong>问题</p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p><strong>持久状态（Hard State）</strong></p><ul><li>currentTerm：像TS一样确定时间</li><li>votedFor：</li><li>log[]：</li></ul><p><strong>易失性状态（Soft State）on All Server</strong></p><ul><li>commitIndex：集群共识的最新commit index</li><li>lastApplied：每个节点应用于自身的最新index</li></ul><p><em>通常有lastApplied &lt;&#x3D; commitIndex</em></p><p><strong>易失性状态 on Leader</strong></p><p><em>Leader给Follower维护的变量</em></p><ul><li>nextIndex[]：下一个要发送的index</li><li>matchIndex[]：已成功发送的index</li></ul><p><strong>AppendEntries RPC</strong></p><ul><li>term：leader当前RPC任期</li><li>leaderID</li><li>prevLogIndex：确认index和term一致，或者定位分歧点，nextIndex - 1</li><li>prevLogTerm：即follower与leader不一致的第一处</li><li>entries[]</li><li>leaderCommit</li></ul><p>return</p><ul><li>success</li><li>term</li></ul><p><strong>RequestVote RPC</strong></p><ul><li>term</li><li>candidateID</li><li>lastLogIndex</li><li>lastLogTerm</li></ul><p>return</p><ul><li>term</li><li>voteGranted：赢得选票</li></ul><h4 id="时间要求"><a href="#时间要求" class="headerlink" title="时间要求"></a>时间要求</h4><blockquote><p>stTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）</p></blockquote><h3 id="Leader-Election-Heartbeats"><a href="#Leader-Election-Heartbeats" class="headerlink" title="Leader Election &amp; Heartbeats"></a>Leader Election &amp; Heartbeats</h3><h4 id="RequestVote"><a href="#RequestVote" class="headerlink" title="RequestVote"></a><strong>RequestVote</strong></h4><p>接收者实现：</p><ol><li>如果<code>term &lt; currentTerm</code>返回 false （老节点）</li><li>如果 votedFor 为空或者为 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（可投票）</li></ol><p><strong>所有服务器需遵守的规则</strong>：</p><p>所有服务器：</p><ul><li>如果<code>commitIndex &gt; lastApplied</code>，则 lastApplied 递增，并将<code>log[lastApplied]</code>应用到状态机中（状态更新到最新）</li><li>如果接收到的 RPC 请求或响应中，任期号<code>T &gt; currentTerm</code>，则令 <code>currentTerm = T</code>，并切换为跟随者状态（遇到新节点，更新状态）</li></ul><p>跟随者（5.2 节）：</p><ul><li>响应来自候选人和领导人的请求</li><li>如果在超过选举超时时间的情况之前没有收到<strong>当前领导人</strong>（即该领导人的任期需与这个跟随者的当前任期相同）的心跳&#x2F;附加日志，或者是给某个候选人投了票，就自己变成候选人</li></ul><p>候选人（5.2 节）：</p><ul><li>在转变成候选人后就立即开始选举过程<ul><li>自增当前的任期号（currentTerm）</li><li>给自己投票</li><li>重置选举超时计时器</li><li>发送请求投票的 RPC 给其他所有服务器</li></ul></li><li>如果接收到大多数服务器的选票，那么就变成领导人</li><li>如果接收到来自新的领导人的附加日志（AppendEntries）RPC，则转变成跟随者</li><li>如果选举过程超时，则再次发起一轮选举</li></ul><p>领导人：</p><ul><li><p>一旦成为领导人：发送空的附加日志（AppendEntries）RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以防止跟随者超时（5.2 节）</p></li><li><p>如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）</p></li><li><p>如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex（</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gauss">lastLogIndex ≥ <span class="hljs-built_in">nextIndex</span><br></code></pre></td></tr></table></figure><p>），则发送从 nextIndex 开始的所有日志条目：</p><ul><li>如果成功：更新相应跟随者的 nextIndex 和 matchIndex</li><li>如果因为日志不一致而失败，则 nextIndex 递减并重试</li></ul></li><li><p>假设存在 N 满足<code>N &gt; commitIndex</code>，使得大多数的 <code>matchIndex[i] ≥ N</code>以及<code>log[N].term == currentTerm</code> 成立，则令 <code>commitIndex = N</code>（5.3 和 5.4 节）</p></li></ul><h4 id="AppendEntries"><a href="#AppendEntries" class="headerlink" title="AppendEntries"></a>AppendEntries</h4><p>接收者的实现：</p><ol><li>返回假 如果领导人的任期小于接收者的当前任期（译者注：这里的接收者是指跟随者或者候选人）（5.1 节）</li><li>返回假 如果接收者日志中没有包含这样一个条目 即该条目的任期在 prevLogIndex 上能和 prevLogTerm 匹配上 （译者注：在接收者日志中 如果能找到一个和 prevLogIndex 以及 prevLogTerm 一样的索引和任期的日志条目 则继续执行下面的步骤 否则返回假）（5.3 节）</li><li>如果一个已经存在的条目和新条目（译者注：即刚刚接收到的日志条目）发生了冲突（因为索引相同，任期不同），那么就删除这个已经存在的条目以及它之后的所有条目 （5.3 节）</li><li>追加日志中尚未存在的任何新条目</li><li>如果领导人的已知已提交的最高日志条目的索引大于接收者的已知已提交最高日志条目的索引（<code>leaderCommit &gt; commitIndex</code>），则把接收者的已知已经提交的最高的日志条目的索引commitIndex 重置为 领导人的已知已经提交的最高的日志条目的索引 leaderCommit 或者是 上一个新条目的索引 取两者的最小值</li></ol><h4 id="ticker"><a href="#ticker" class="headerlink" title="ticker"></a>ticker</h4><p>计时确保选举和心跳顺利进行</p><h4 id="sendHeartbeat"><a href="#sendHeartbeat" class="headerlink" title="sendHeartbeat"></a>sendHeartbeat</h4><p>同步Follower日志，特殊的AppendEntries</p><h3 id="Log日志"><a href="#Log日志" class="headerlink" title="Log日志"></a>Log日志</h3><blockquote><p>Life is Append-Only</p></blockquote><p>如何设置一个协程触发AppendEntries?</p><h4 id="ApplyChannel-ApplyMsg"><a href="#ApplyChannel-ApplyMsg" class="headerlink" title="ApplyChannel &amp; ApplyMsg"></a>ApplyChannel &amp; ApplyMsg</h4><p>实现了<strong>Raft</strong>和<strong>状态机</strong>之间的解耦，负责打包传递复制的日志。</p><p>实际上本程序仅实现了状态机内部的功能，外部的接口和调用还需观察。</p><p>外部通过<strong>applyCh</strong>获得更新的日志，并且检查？</p><p>当commitIndex更新时，需要解开<strong>applyCond</strong>进行及时传递。</p><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><h2 id="数据库优化"><a href="#数据库优化" class="headerlink" title="数据库优化"></a>数据库优化</h2><p>​面试总结：SRE岗位</p><h4 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h4><p>作为一名计算机科学专业的学生，我参与了2024年全国大学生计算机系统能力大赛PolarDB数据库创新设计赛（天池杯），负责数据库性能优化工作。我们的目标是通过多种优化策略，将PolarDB在TPC-H基准测试中的性能提升78.5%。以下是我在项目中的主要贡献和经验总结，以及如何将这些经验应用于SRE岗位。</p><h4 id="项目经验与SRE相关性"><a href="#项目经验与SRE相关性" class="headerlink" title="项目经验与SRE相关性"></a>项目经验与SRE相关性</h4><ol><li><p><strong>系统优化与性能提升</strong></p><ul><li><p><strong>参数优化：</strong> 调整数据库配置参数，如内存使用、并行设置等，确保系统在高负载下稳定运行。这与SRE的核心职责——优化系统性能和可靠性——高度契合。</p></li><li><p><strong>编译优化：</strong> 通过关闭调试模式和采用O3优化，显著提升查询速度。这体现了我对系统底层优化的理解，有助于在SRE岗位中优化生产环境中的系统性能。</p><blockquote><p>编译优化：循环优化，内联，SIMD，数据对齐，缓存读取</p></blockquote></li><li><p><strong>查询优化：</strong> 重写SQL语句，使用CTE替代子查询，减少资源消耗。这展示了我在提高系统效率方面的技能，对SRE中的性能优化和应急响应有直接帮助。</p></li></ul></li><li><p><strong>系统监控与分析</strong></p><ul><li><strong>性能监控：</strong> 使用指标如查询响应时间、系统资源利用率等，监控优化效果。这与SRE中使用监控工具（如Prometheus、Grafana）分析系统状态相似。</li><li><strong>日志分析：</strong> 通过分析日志，识别性能瓶颈和潜在问题。这与SRE中通过日志排查系统故障的经验一致。</li></ul></li><li><p><strong>自动化与工具开发</strong></p><ul><li><strong>脚本编写：</strong> 开发自动化脚本（如<code>tpch_copy.sh</code>和<code>polardb_build.sh</code>），简化数据导入和数据库初始化流程。这体现了我在自动化运维方面的技能，对SRE中的自动化部署和维护至关重要。</li><li><strong>工具集成：</strong> 尝试集成DuckDB与PolarDB，虽然未成功，但积累的经验帮助我理解不同数据库间的兼容性和集成挑战。这对SRE中的工具链整合和优化有参考价值。</li></ul></li><li><p><strong>故障排除与应急响应</strong></p><ul><li><strong>失败尝试分析：</strong> 在尝试内存列存储和DuckDB集成时遇到问题，通过分析失败原因，调整优化策略。这培养了我在面对系统故障时的分析和解决问题的能力，对SRE中的应急响应和故障排除有直接帮助。</li><li><strong>系统回滚：</strong> 在优化过程中，确保能够快速回滚到稳定版本。这体现了我对系统变更的谨慎态度，对SRE中的版本管理和风险控制有借鉴意义。</li></ul></li></ol><h4 id="具体贡献与经验总结"><a href="#具体贡献与经验总结" class="headerlink" title="具体贡献与经验总结"></a>具体贡献与经验总结</h4><ol><li><strong>参数优化</strong><ul><li><strong>贡献：</strong> 调整内存使用、并行设置和日志配置，优化系统资源分配，提升查询性能。</li><li><strong>经验：</strong> 参数调整需要综合考虑系统负载、资源限制和业务需求，避免过度优化导致的不可靠性。</li></ul></li><li><strong>编译优化</strong><ul><li><strong>贡献：</strong> 关闭调试模式，采用O3优化，提升查询速度。</li><li><strong>经验：</strong> 编译优化对系统性能有显著影响，但在生产环境中需要权衡性能和调试能力。</li></ul></li><li><strong>查询优化</strong><ul><li><strong>贡献：</strong> 重写复杂查询，使用CTE和物化视图，减少中间结果集大小，提升查询效率。</li><li><strong>经验：</strong> 了解数据库执行计划和优化器行为是提升查询性能的关键。</li></ul></li><li><strong>内核优化</strong><ul><li><strong>贡献：</strong> 引入列存储和分区表优化，提升数据读取效率。</li><li><strong>经验：</strong> 系统内核优化需要深入了解数据库存储机制和查询执行流程。</li></ul></li><li><strong>失败尝试</strong><ul><li><strong>内存列存储：</strong> 尝试使用内存列存储加速查询，但因数据加载和系统重启问题放弃。</li><li><strong>经验：</strong> 在选择技术方案时，需评估其对系统可靠性和维护成本的影响。</li><li><strong>DuckDB集成：</strong> 尝试将DuckDB与PolarDB集成，但因存储格式和优化器不兼容失败。</li><li><strong>经验：</strong> 集成不同系统时，需充分考虑其底层实现和兼容性问题。</li></ul></li></ol><h4 id="从项目到SRE的技能迁移"><a href="#从项目到SRE的技能迁移" class="headerlink" title="从项目到SRE的技能迁移"></a>从项目到SRE的技能迁移</h4><ol><li><strong>系统优化与性能提升</strong><ul><li><strong>技能迁移：</strong> 在SRE岗位中，优化系统性能以提升可靠性是核心任务。我通过参数和查询优化积累了丰富的经验，能够快速识别和解决生产环境中的性能瓶颈。</li></ul></li><li><strong>自动化运维</strong><ul><li><strong>技能迁移：</strong> 自动化是SRE工作的基石。我开发的自动化脚本培养了我编写高效运维工具的能力，能够快速实现任务自动化，减少人为错误。</li></ul></li><li><strong>监控与分析</strong><ul><li><strong>技能迁移：</strong> 熟练使用监控工具分析系统状态，快速定位问题。我通过性能监控和日志分析积累了丰富的经验，能够有效应对系统故障。</li></ul></li><li><strong>故障排除与应急响应</strong><ul><li><strong>技能迁移：</strong> 在项目中处理失败尝试和系统回滚的经历，培养了我冷静分析和快速解决问题的能力，这对SRE中的应急响应至关重要。</li></ul></li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>通过参与PolarDB数据库优化项目，我积累了丰富的系统优化、监控、自动化运维和故障排除经验，这些能力与SRE的核心职责高度契合。我有信心将这些经验应用到实际工作中，为团队的系统可靠性提升和持续改进做出贡献。</p><h2 id="CMU15445"><a href="#CMU15445" class="headerlink" title="CMU15445"></a>CMU15445</h2><h3 id="Buffer-Pool"><a href="#Buffer-Pool" class="headerlink" title="Buffer Pool"></a>Buffer Pool</h3><h4 id="LRU-K"><a href="#LRU-K" class="headerlink" title="LRU-K"></a>LRU-K</h4><p>冷热数据分离，维护一个访问大于等于K和一个小于K的优先队列。</p><p>计数型互斥锁</p><h4 id="Disk-Scheduler"><a href="#Disk-Scheduler" class="headerlink" title="Disk Scheduler"></a>Disk Scheduler</h4><p>简单的队列</p><h4 id="Buffer-Pool-Manager"><a href="#Buffer-Pool-Manager" class="headerlink" title="Buffer Pool Manager"></a>Buffer Pool Manager</h4><ul><li><code>FetchPage(page_id_t page_id)</code>：给定pageid返回物理页。先查看缓存page table，没有则进入磁盘获取，顺便加入缓存。和NewPage很像。</li><li><code>UnpinPage(page_id_t page_id, bool is_dirty)</code>：计数互斥锁，记得设置Evictable</li><li><code>FlushPage(page_id_t page_id)</code>：写入对应pageid的数据</li><li><code>NewPage(page_id_t* page_id)</code>：在缓存池中创建一个新page</li><li><code>DeletePage(page_id_t page_id)</code>：注意上锁，释放page和对应frame</li><li><code>FlushAllPages()</code>：把缓存的page全部刷入磁盘</li></ul><h3 id="Extendible-Hash-Index"><a href="#Extendible-Hash-Index" class="headerlink" title="Extendible Hash Index"></a>Extendible Hash Index</h3><h4 id="R-W-Page-Guards"><a href="#R-W-Page-Guards" class="headerlink" title="R&#x2F;W Page Guards"></a>R&#x2F;W Page Guards</h4><p>RAII</p><h4 id="Extendible-Hash-Table-Pages"><a href="#Extendible-Hash-Table-Pages" class="headerlink" title="Extendible Hash Table Pages"></a>Extendible Hash Table Pages</h4><table><thead><tr><th>Variable Name</th><th>Size</th><th>Description</th></tr></thead><tbody><tr><td><code>max_depth_</code></td><td>4</td><td>The maximum depth the header page could handle</td></tr><tr><td><code>global_depth_</code></td><td>4</td><td>The current directory global depth</td></tr><tr><td><code>local_depths_</code></td><td>512</td><td>An array of bucket page local depths</td></tr><tr><td><code>bucket_page_ids_</code></td><td>2048</td><td>An array of bucket page ids</td></tr></tbody></table><p>难点在于<strong>分裂</strong>与<strong>合并</strong></p><ul><li>Global Depth：用几位来分类，这几位必须不同</li><li>Local Depth：相同的几位将会被分在同一个桶里</li></ul><p>e.g. GD&#x3D;3，LD&#x3D;2，则1000和1100被分到同一个桶，LD&lt;&#x3D;GD</p><p>如果扩容到LD&#x3D;3，则新的桶位置id是：0000和1000，一个加0，一个加上1&lt;&lt;(LD-1)即可</p><h4 id="Extendible-Hashing-Implementation"><a href="#Extendible-Hashing-Implementation" class="headerlink" title="Extendible Hashing Implementation"></a>Extendible Hashing Implementation</h4><p>一个Extendible Hash Table需要什么？</p><p>层层打开的Hash结构，注意对应的RWPageGuard</p><ul><li><p>Insert：插入新的dir和bucket。判断扩容，扩容时数据的迁移</p><p>new dir?使用newpage申请并升级</p></li><li><p>Remove：和insert一样都是基于bucket的函数操作，但是要注意shrink条件</p><p>bucket为空，LD&#x3D;&#x3D;GD（这个bucket不被需要了），递归进行：</p><p>DecLD，更新映射 dir-&gt;bucket ，移动原bucket</p></li><li><p>SplitBucket：</p></li></ul><h2 id="小狗屎后端"><a href="#小狗屎后端" class="headerlink" title="小狗屎后端"></a>小狗屎后端</h2>]]></content>
    
    
    
    <tags>
      
      <tag>项目</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis</title>
    <link href="/2025/03/01/Redis/"/>
    <url>/2025/03/01/Redis/</url>
    
    <content type="html"><![CDATA[<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>实现方式：</p><ul><li>AOF日志：Append Only File，执行一条写一条日志。所以是在写完日志之后，记录做过的事。AOF丢失少，恢复慢。</li><li>RDB快照：全量快照，影响性能。</li><li>混合方式：RDB负责前半全量数据，减少能耗、快速恢复。AOF负责后半增量数据。</li></ul><h3 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a>脑裂</h3><p><em>由于网络问题产生多个Leader</em>，旧Leader写入数据被新Leader的同步清除了</p><p><strong>解决方案</strong></p><p>在可能发生故障时限制写入</p><p>节点数量&lt;N 或 通信时长&gt;T</p><h4 id="Extra-Money"><a href="#Extra-Money" class="headerlink" title="Extra Money"></a>Extra Money</h4><p><strong>跳表</strong></p><p>​很好地解释了什么是跳表，一个每次跳跃2^n的二维数组<img src="https://picx.zhimg.com/v2-be424e42c99fde208c835d565499c3d7_1440w.jpg" alt="img"></p><p>和平衡二叉树不同的是，跳表使用概率达成均衡。每个节点有1&#x2F;skip的概率添加至上一层。</p><p><strong>RedBlack Tree</strong></p><p><em>为什么Redis使用跳表而不是红黑树？</em></p><ul><li>实现难度，维护成本</li><li>查询高效</li><li>并发扩展</li><li>概率平衡&#x2F;严格平衡</li></ul><h2 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h2><p><strong>过期字典</strong>：给设置过期时间的Key放在里面，查询时优先查找Expire Dict，比对过期时间</p><p><strong>惰性删除+定期删除</strong></p><p>​访问时过期才删除</p><p>​随机抽取，看看过期的占比。如果占比过多则重复删除。否则仅删除一轮</p><p><strong>RDB淘汰策略</strong></p><ul><li>新的RDB文件生成时会淘汰</li><li>主服务器淘汰。从服务器不主动淘汰，除非主服务器同步清除（DEL指令）</li></ul><p><strong>AOF淘汰策略</strong></p><ul><li>写入时保留过期键，等其被删除再追加DEL指令</li><li>重写时淘汰过期键</li></ul><p><strong>LRU LFU</strong></p><h2 id="缓存设计"><a href="#缓存设计" class="headerlink" title="缓存设计"></a>缓存设计</h2><h3 id="缓存保护"><a href="#缓存保护" class="headerlink" title="缓存保护"></a>缓存保护</h3><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h4><p>缓存雪崩是指在某一时间段内，大量缓存数据<strong>同时失效</strong>或<strong>缓存系统宕机</strong>，导致所有请求直接涌向数据库，造成数据库瞬时压力激增甚至崩溃的现象。</p><p><strong>解决方案</strong></p><ol><li><strong>失效时间随机化</strong>：在基础过期时间上增加随机偏移值（如：基础300秒±随机120秒）</li><li><strong>分级缓存架构</strong>：采用L1&#x2F;L2缓存分级，L1设置短时间，L2设置长时间</li><li><strong>热点数据永不过期</strong>：配合异步更新机制维护数据一致性</li><li><strong>熔断降级机制</strong>：使用Hystrix或Sentinel实现请求限流</li><li><strong>集群高可用</strong>：Redis Cluster模式部署，保证单节点故障不影响整体服务</li></ol><h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a><strong>缓存击穿</strong></h4><p>某个超高热点的缓存突然失效，导致<strong>海量请求直接冲击数据库</strong>，形成”单点爆破”效应。</p><p><strong>解决方案</strong></p><ul><li><p><strong>互斥锁（Mutex Lock）</strong>：仅允许一个线程通过查询重建缓存，其他线程等待后重试。</p><p><em>互斥锁仅针对数据库请求</em></p></li><li><p><strong>逻辑过期</strong>：缓存永不过期，但存储逻辑过期时间，由后台线程异步更新。</p></li><li><p><strong>缓存预热</strong>：在高峰前预先加载热点数据。</p></li></ul><h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a><strong>缓存穿透</strong></h4><p>大量请求查询<strong>数据库中不存在的数据</strong>，导致缓存无法命中，请求直接穿透到数据库。</p><p><strong>解决方案</strong></p><ul><li><strong>空值缓存</strong>：对查询结果为null的键，缓存短TTL的空值（如 <code>redis.set(key, null, 60)</code>）。</li><li><strong>布隆过滤器（Bloom Filter）</strong>：在缓存层前加过滤器，快速拦截无效请求。</li><li><strong>参数校验</strong>：对请求参数进行格式、范围校验（如ID必须为正整数）。</li></ul><h3 id="缓存更新策略"><a href="#缓存更新策略" class="headerlink" title="缓存更新策略"></a>缓存更新策略</h3><ul><li><p>Catch Aside：优先改变数据库，然后更新缓存</p><p><em><strong>为什么先数据库后缓存？</strong></em></p><p>源数据不更改，缓存始终跟着走。而且更新缓存比数据库快多了</p></li><li><p>R&#x2F;W Through：仅和缓存交互。其余交给缓存组件（不常见）</p></li><li><p>Write Back：批量异步更新脏缓存，写得快，容易丢数据</p></li></ul><h2 id="实战！！！"><a href="#实战！！！" class="headerlink" title="实战！！！"></a>实战！！！</h2><h3 id="大Key问题"><a href="#大Key问题" class="headerlink" title="大Key问题"></a>大Key问题</h3><p><strong>Key的Value很大</strong></p><ul><li>客户端超时</li><li>网络阻塞</li><li>工作线程阻塞</li><li>内存分布不均</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Redis</tag>
      
      <tag>面经</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据库的锁</title>
    <link href="/2025/02/27/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%94%81/"/>
    <url>/2025/02/27/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%94%81/</url>
    
    <content type="html"><![CDATA[<h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h2><p>让数据库变成read only</p><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><ol><li>表锁：给表加锁，同时本线程无法访问其他表</li><li>元数据锁：对表操作隐式使用</li><li>意向锁：行级锁之前，快速判断有无记录被加锁</li><li>AUTO-INC锁：用于自增类型的加锁，不然容易出错</li></ol><h2 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h2><ol><li>Record Lock：锁记录</li><li>Gap Lock：锁范围（开区间）。间隙锁之间是兼容的的，可以由多个事务持有重复区间的间隙锁。</li><li>Next-Key Lock：记录锁+间隙锁（一开一闭）。既保护了当前记录，又阻止间隙之间有新值插入。</li><li>插入意向锁：用于插入时占用锁等待队列。</li></ol><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>一致性，有效性，防止脑裂-&gt;过半节点同意。</p><h3 id="基于Redis"><a href="#基于Redis" class="headerlink" title="基于Redis"></a>基于Redis</h3><p>设置一个公共的Key和对应过期时间。Key&#x3D;0可以获得锁，否则不行。</p><h2 id="加锁时机"><a href="#加锁时机" class="headerlink" title="加锁时机"></a>加锁时机</h2><p>select update…</p><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>两个事务获得了公共的间隙锁，但是插入意向锁和对方的间隙锁起了冲突。</p><p><strong>解决方案</strong></p><ol><li>降低隔离级别，RC就不会使用gap lock</li><li>使用唯一索引，避免全表扫描…</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>分布式系统</tag>
      
      <tag>面经</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>四种隔离级别的思考</title>
    <link href="/2025/02/26/Txn/"/>
    <url>/2025/02/26/Txn/</url>
    
    <content type="html"><![CDATA[<h1 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h1><p>整体分为：</p><ol><li>读未提交</li><li>读已提交</li><li>可重复读</li><li>串行化</li></ol><h2 id="可能产生的问题"><a href="#可能产生的问题" class="headerlink" title="可能产生的问题"></a>可能产生的问题</h2><ol><li>脏读：读到其他事务未提交的数据，容易理解</li><li>不可重复读：多次读同一行内容不一致</li><li>幻读：多次读某个范围的数据，范围不一致（有插入删除）</li></ol><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><p>脏读和不可重复度：脏读可以认为事务B单次读取数据，读到事务A修改但未提交的数据。不可重复读可以看作事务B在事务A修改前后分别读了一次，得到的数据自然不同。</p><p>不可重复读和幻读：不可重复读按照上述，主要冲突在一次事务内读同一行两次数据不同。幻读可以认为是事务B读取某一范围的数据，而事务A在B的两次读取之间对该范围插入或删除了数据。产生一次读2条，第二次读3条的错误。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>通过产生的原因可以想到对应解决办法</p><h3 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h3><p>通过MVCC（读快照），避免读到其他事务做出的修改。</p><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p>MVCC给每个事务生成最新快照，避免事务之间互相影响。</p><h3 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h3><p>MVCC无法拦住边读边写的幻读。当数据出现更新，会悄悄把更新数据加进来。因此需要间隙锁或临键锁。</p><ol><li>间隙锁：范围锁，比如查询age&gt;20，会锁住(20,+inf)阻隔新数据加入&#x2F;旧数据修改。</li><li>临键锁：范围+当前键，比如age&gt;20，可以得到[20,+inf)</li></ol><h2 id="为什么有四种"><a href="#为什么有四种" class="headerlink" title="为什么有四种"></a>为什么有四种</h2><p><strong>为什么有四种隔离级别？既然低级别会产生错误，直接上高级别一刀切不就好了？</strong></p><p>数据库性能与一致性的互相妥协。</p>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>面经</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>raft</title>
    <link href="/2025/02/24/raft/"/>
    <url>/2025/02/24/raft/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>这是一个测试</title>
    <link href="/2025/02/24/%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95/"/>
    <url>/2025/02/24/%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h1 id="这是一个测试"><a href="#这是一个测试" class="headerlink" title="这是一个测试"></a>这是一个测试</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello world\n&quot;</span>);<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="标题1"><a href="#标题1" class="headerlink" title="标题1"></a>标题1</h2><h3 id="标题2"><a href="#标题2" class="headerlink" title="标题2"></a>标题2</h3>]]></content>
    
    
    <categories>
      
      <category>测试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>测试1</tag>
      
      <tag>测试2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试</title>
    <link href="/2025/02/24/%E6%B5%8B%E8%AF%95/"/>
    <url>/2025/02/24/%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/02/24/hello-world/"/>
    <url>/2025/02/24/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
